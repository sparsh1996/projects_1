{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INdependence.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwNKQxhE_gjM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d2380a0b-6f20-4e77-e8f0-66b09fc88ac3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import seaborn as sn\n",
        "import datetime as dt\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from keras import backend as K\n",
        "import re\n",
        "from sklearn.utils import resample\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from itertools import combinations\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error, SCORERS, precision_recall_curve, f1_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from sklearn.linear_model import Lasso, LassoLars, LinearRegression, Ridge\n",
        "from lightgbm import LGBMClassifier, LGBMRegressor\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier, XGBRegressor, XGBRFRegressor\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoTlohKrGmld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_dyAZdsJIpj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "2ce3d697-0f32-42e3-e429-5249fe6ca501"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/df/ab6d927d6162657f30eb0ae3c534c723c28c191a9caf6ee68ec935df3d0b/bert-for-tf2-0.14.5.tar.gz (40kB)\n",
            "\r\u001b[K     |████████                        | 10kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 30kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 2.8MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.5-cp36-none-any.whl size=30315 sha256=9cee698cf3674a454d71f09daa578239efb3fd7e804dfa99659caa17ed5b799c\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/70/a2/be357037dd2cbdcaeb0add1fdf083be6a600ca65ee1f68751c\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7302 sha256=6038852ad4af19f162bb3cc09559202e17638570c9641af8a2ac7286dae53fdd\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19473 sha256=eb9cd996266c2ff3ed17ddb075fe196b3c2442d68c14c7a2ec673465161d50eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.5 params-flow-0.8.2 py-params-0.9.7\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 6.4MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPvLDGy_AGHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras import layers, models, optimizers, regularizers\n",
        "import bert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxhlPNVHEfOp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "03d8c837-e1b5-405c-a926-53b8084494ce"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPxvC9dNJ0M0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/independence/data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM8QLgl2KgYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.drop('Unnamed: 0', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMV9SdTTKioi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "e32e9cfa-3ae7-4e76-f81a-015fea765745"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABSTRACT</th>\n",
              "      <th>Computer Science</th>\n",
              "      <th>Physics</th>\n",
              "      <th>Mathematics</th>\n",
              "      <th>Statistics</th>\n",
              "      <th>Quantitative Biology</th>\n",
              "      <th>Quantitative Finance</th>\n",
              "      <th>new_text</th>\n",
              "      <th>title_abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
              "      <td>Predictive models allow subject-specific inf...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>reconstructing subject specific effect maps pr...</td>\n",
              "      <td>Reconstructing Subject-Specific Effect Maps  P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rotation Invariance Neural Network</td>\n",
              "      <td>Rotation invariance and translation invarian...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>rotation invariance neural network rotation in...</td>\n",
              "      <td>Rotation Invariance Neural Network  Rotation i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
              "      <td>We introduce and develop the notion of spher...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>spherical polyharmonics and poisson kernels fo...</td>\n",
              "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A finite element approximation for the stochas...</td>\n",
              "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>finite element approximation for the stochasti...</td>\n",
              "      <td>A finite element approximation for the stochas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
              "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>comparative study discrete wavelet transforms ...</td>\n",
              "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               TITLE  ...                                     title_abstract\n",
              "0        Reconstructing Subject-Specific Effect Maps  ...  Reconstructing Subject-Specific Effect Maps  P...\n",
              "1                 Rotation Invariance Neural Network  ...  Rotation Invariance Neural Network  Rotation i...\n",
              "2  Spherical polyharmonics and Poisson kernels fo...  ...  Spherical polyharmonics and Poisson kernels fo...\n",
              "3  A finite element approximation for the stochas...  ...  A finite element approximation for the stochas...\n",
              "4  Comparative study of Discrete Wavelet Transfor...  ...  Comparative study of Discrete Wavelet Transfor...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50uOI7S3Krys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['title_abstract'] = data.TITLE + data.ABSTRACT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLmsWLesKxY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pat3 = re.compile(r'[_,-]')\n",
        "pat = re.compile(r'\\w{3,}')\n",
        "pat4 = re.compile('\\D+')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE4xeoU-LQzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = list(STOP_WORDS)\n",
        "stop_words.extend(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY7_l4ACLYC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['new_text'] = data['new_text'].map(lambda x:pat3.sub(\"\",x))\n",
        "data['new_text'] = data['new_text'].map(lambda x:' '.join(pat.findall(x)))\n",
        "data['new_text'] = data['new_text'].map(lambda x:''.join(pat4.findall(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwmp4U0QLwku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "9ec036db-7416-4953-a359-17a0d4289f93"
      },
      "source": [
        "data['title_abstract'] = data['title_abstract'].map(lambda x: re.sub(r'[^A-Za-z]', ' ', x).lower())\n",
        "data['title_abstract'] = data['title_abstract'].map(lambda x: re.sub(r\" +\", ' ', x))\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABSTRACT</th>\n",
              "      <th>Computer Science</th>\n",
              "      <th>Physics</th>\n",
              "      <th>Mathematics</th>\n",
              "      <th>Statistics</th>\n",
              "      <th>Quantitative Biology</th>\n",
              "      <th>Quantitative Finance</th>\n",
              "      <th>new_text</th>\n",
              "      <th>title_abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
              "      <td>Predictive models allow subject-specific inf...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>reconstructing subject specific effect maps pr...</td>\n",
              "      <td>reconstructing subject specific effect maps pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rotation Invariance Neural Network</td>\n",
              "      <td>Rotation invariance and translation invarian...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>rotation invariance neural network rotation in...</td>\n",
              "      <td>rotation invariance neural network rotation in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
              "      <td>We introduce and develop the notion of spher...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>spherical polyharmonics and poisson kernels fo...</td>\n",
              "      <td>spherical polyharmonics and poisson kernels fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A finite element approximation for the stochas...</td>\n",
              "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>finite element approximation for the stochasti...</td>\n",
              "      <td>a finite element approximation for the stochas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
              "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>comparative study discrete wavelet transforms ...</td>\n",
              "      <td>comparative study of discrete wavelet transfor...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               TITLE  ...                                     title_abstract\n",
              "0        Reconstructing Subject-Specific Effect Maps  ...  reconstructing subject specific effect maps pr...\n",
              "1                 Rotation Invariance Neural Network  ...  rotation invariance neural network rotation in...\n",
              "2  Spherical polyharmonics and Poisson kernels fo...  ...  spherical polyharmonics and poisson kernels fo...\n",
              "3  A finite element approximation for the stochas...  ...  a finite element approximation for the stochas...\n",
              "4  Comparative study of Discrete Wavelet Transfor...  ...  comparative study of discrete wavelet transfor...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpTigZz8PiEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = data.iloc[:, 2:8].dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpRM0r_4PyG-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "db20c14c-f0a9-4fcc-9d05-86e8f4dcd628"
      },
      "source": [
        "print(target['Computer Science'].value_counts(),'\\n')\n",
        "print(target['Physics'].value_counts(), '\\n') \n",
        "print(target['Mathematics'].value_counts(), '\\n') \n",
        "print(target['Statistics'].value_counts(), '\\n')\n",
        "print(target['Quantitative Biology'].value_counts(), '\\n')\n",
        "print(target['Quantitative Finance'].value_counts(), '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0    12378\n",
            "1.0     8594\n",
            "Name: Computer Science, dtype: int64 \n",
            "\n",
            "0.0    14959\n",
            "1.0     6013\n",
            "Name: Physics, dtype: int64 \n",
            "\n",
            "0.0    15354\n",
            "1.0     5618\n",
            "Name: Mathematics, dtype: int64 \n",
            "\n",
            "0.0    15766\n",
            "1.0     5206\n",
            "Name: Statistics, dtype: int64 \n",
            "\n",
            "0.0    20385\n",
            "1.0      587\n",
            "Name: Quantitative Biology, dtype: int64 \n",
            "\n",
            "0.0    20723\n",
            "1.0      249\n",
            "Name: Quantitative Finance, dtype: int64 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhBsappPVleA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fulltokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2', trainable=False)\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "tokenizer = fulltokenizer(vocab_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixk5G7IMdifW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f4685b7-a08a-47ee-def3-756002d1c03d"
      },
      "source": [
        "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"my name is going to be sparsh\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2026, 2171, 2003, 2183, 2000, 2022, 12403, 2869, 2232]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqao5rwfeAc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_sentence(sent):\n",
        "  return [\"[CLS]\"]+tokenizer.tokenize(sent)+[\"[SEP]\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_GWPE-PeaSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_input = [encode_sentence(sentence) for sentence in data.title_abstract]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeTugcjf0r2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ids(tokens):\n",
        "  return tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "def get_mask(tokens):\n",
        "  return np.char.not_equal(tokens, \"[PAD]\").astype('int')  \n",
        "\n",
        "def get_segments(tokens):\n",
        "  seg_ids = []\n",
        "  current_seg_id = 0\n",
        "  for tok in tokens:\n",
        "    seg_ids.append(current_seg_id)\n",
        "    if tok == \"[SEP]\":\n",
        "      current_seg_id = 1-current_seg_id  \n",
        "  return seg_ids  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUwwctHw5CjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_with_len = [[sent, target['Computer Science'][i], len(sent)]\n",
        "                 for i, sent in enumerate(text_input[:20972])]\n",
        "random.shuffle(data_with_len)\n",
        "data_with_len.sort(key=lambda x: x[2])\n",
        "sorted_all = [([get_ids(sent_lab[0]),\n",
        "                get_mask(sent_lab[0]),\n",
        "                get_segments(sent_lab[0])],\n",
        "               sent_lab[1])\n",
        "              for sent_lab in data_with_len if sent_lab[2] > 7]\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgqDczKADu-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_with_len_test = [[sent, len(sent)]\n",
        "                 for i, sent in enumerate(text_input[20972:])]\n",
        "\n",
        "sorted_all_test = [([get_ids(sent_lab[0]),\n",
        "                get_mask(sent_lab[0]),\n",
        "                get_segments(sent_lab[0])],\n",
        "               sent_lab[1])\n",
        "              for sent_lab in data_with_len_test]        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruutRio55fub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "67f07699-c2bc-4117-b481-1c614a78040b"
      },
      "source": [
        "sorted_all[0][0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 2784,\n",
              " 15756,\n",
              " 6125,\n",
              " 1037,\n",
              " 4766,\n",
              " 2381,\n",
              " 4955,\n",
              " 2000,\n",
              " 2784,\n",
              " 15756,\n",
              " 6125,\n",
              " 1998,\n",
              " 2037,\n",
              " 2381,\n",
              " 102]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K0aPK538yI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A list is a type of iterator so it can be used as generator for a dataset\n",
        "all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,\n",
        "                                             output_types=(tf.int32, tf.int32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G24SYIvDHgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "all_batched = all_dataset.padded_batch(BATCH_SIZE,\n",
        "                                       padded_shapes=((3, None), ()),\n",
        "                                       padding_values=(0, 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJuXvEVREGxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NB_BATCHES = np.math.ceil(len(sorted_all) / BATCH_SIZE)\n",
        "NB_BATCHES_TEST = NB_BATCHES // 10\n",
        "all_batched.shuffle(NB_BATCHES)\n",
        "test_dataset = all_batched.take(NB_BATCHES_TEST)\n",
        "val_dataset = all_batched.take(NB_BATCHES_TEST)\n",
        "train_dataset = all_batched.skip(NB_BATCHES_TEST)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAFeeix4EStn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "d56028c3-0d95-44ef-8e5a-ffe2acdf0bf7"
      },
      "source": [
        "next(iter(val_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 3, 29), dtype=int32, numpy=\n",
              " array([[[  101,  2784, 15756, ...,     0,     0,     0],\n",
              "         [    1,     1,     1, ...,     0,     0,     0],\n",
              "         [    0,     0,     0, ...,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  5110,  2522, ...,     0,     0,     0],\n",
              "         [    1,     1,     1, ...,     0,     0,     0],\n",
              "         [    0,     0,     0, ...,     0,     0,     0]],\n",
              " \n",
              "        [[  101, 15182,  1999, ...,     0,     0,     0],\n",
              "         [    1,     1,     1, ...,     0,     0,     0],\n",
              "         [    0,     0,     0, ...,     0,     0,     0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  101,  1996,  2832, ...,  4730,  2653,   102],\n",
              "         [    1,     1,     1, ...,     1,     1,     1],\n",
              "         [    0,     0,     0, ...,     0,     0,     0]],\n",
              " \n",
              "        [[  101, 10124,  9972, ..., 10124,  9972,   102],\n",
              "         [    1,     1,     1, ...,     1,     1,     1],\n",
              "         [    0,     0,     0, ...,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  1996, 20248, ...,  2389, 19287,   102],\n",
              "         [    1,     1,     1, ...,     1,     1,     1],\n",
              "         [    0,     0,     0, ...,     0,     0,     0]]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 1, 0, 1], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ2uocVLimQQ",
        "colab_type": "text"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmn_AkwqhWyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCNNBERTEmbedding(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 nb_filters=50,\n",
        "                 FFN_units=512,\n",
        "                 nb_classes=2,\n",
        "                 dropout_rate=0.1,\n",
        "                 name=\"dcnn\"):\n",
        "        super(DCNNBERTEmbedding, self).__init__(name=name)\n",
        "        \n",
        "        self.bert_layer = hub.KerasLayer(\n",
        "            \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "            trainable=False)\n",
        "        \n",
        "        self.unigram = layers.Conv1D(filters=nb_filters,\n",
        "                                    kernel_size=1,\n",
        "                                    padding=\"valid\",\n",
        "                                    activation=\"relu\")\n",
        "\n",
        "        self.bigram = layers.Conv1D(filters=nb_filters,\n",
        "                                    kernel_size=2,\n",
        "                                    padding=\"valid\",\n",
        "                                    activation=\"relu\")\n",
        "        self.trigram = layers.Conv1D(filters=nb_filters,\n",
        "                                     kernel_size=3,\n",
        "                                     padding=\"valid\",\n",
        "                                     activation=\"relu\")\n",
        "        self.fourgram = layers.Conv1D(filters=nb_filters,\n",
        "                                      kernel_size=4,\n",
        "                                      padding=\"valid\",\n",
        "                                      activation=\"relu\")\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\", kernel_regularizer=regularizers.l1_l2(l1=0.5, l2=0.5))\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        self.dense_1 = layers.Dense(units=FFN_units*2, activation=\"relu\", kernel_regularizer=regularizers.l1_l2(l1=0.5, l2=0.5))\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        self.dense_1 = layers.Dense(units=FFN_units*3, activation=\"relu\", kernel_regularizer=regularizers.l1_l2(l1=0.5, l2=0.5))\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        if nb_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                                           activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=nb_classes,\n",
        "                                           activation=\"softmax\")\n",
        "    \n",
        "    def embed_with_bert(self, all_tokens):\n",
        "        _, embs = self.bert_layer([all_tokens[:, 0, :],\n",
        "                                   all_tokens[:, 1, :],\n",
        "                                   all_tokens[:, 2, :]])\n",
        "        return embs\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        x = self.embed_with_bert(inputs)\n",
        "\n",
        "        x_1 = self.bigram(x)\n",
        "        x_1 = self.pool(x_1)\n",
        "        x_2 = self.trigram(x)\n",
        "        x_2 = self.pool(x_2)\n",
        "        x_3 = self.fourgram(x)\n",
        "        x_3 = self.pool(x_3)\n",
        "        \n",
        "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\n",
        "        merged = self.dense_1(merged)\n",
        "        merged = self.dropout(merged, training)\n",
        "        output = self.last_dense(merged)\n",
        "        \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHMftzMFEpyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NB_FILTERS = 100\n",
        "FFN_UNITS = 128\n",
        "NB_CLASSES = 2\n",
        "\n",
        "DROPOUT_RATE = 0.5\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NB_EPOCHS = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFpOywU8p38z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xLwQ6WXrPP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Dcnn = DCNNBERTEmbedding(nb_filters=NB_FILTERS,\n",
        "                         FFN_units=FFN_UNITS,\n",
        "                         nb_classes=NB_CLASSES,\n",
        "                         dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7dVaTRTsjUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if NB_CLASSES == 2:\n",
        "    Dcnn.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"rmsprop\",\n",
        "                 metrics=[\"accuracy\", f1])\n",
        "else:\n",
        "    Dcnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9Su4qwjtNmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "60a916fc-fed9-42a1-9ad6-c8c37de16460"
      },
      "source": [
        "Dcnn.fit(train_dataset,\n",
        "         epochs=NB_EPOCHS, validation_data=val_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "591/591 [==============================] - 535s 905ms/step - loss: 145.6824 - accuracy: 0.6966 - f1: 0.5860 - val_loss: 29.7431 - val_accuracy: 0.7726 - val_f1: 0.5497\n",
            "Epoch 2/5\n",
            "591/591 [==============================] - 535s 905ms/step - loss: 29.5083 - accuracy: 0.7021 - f1: 0.5393 - val_loss: 29.1003 - val_accuracy: 0.8683 - val_f1: 0.5686\n",
            "Epoch 3/5\n",
            "591/591 [==============================] - 534s 904ms/step - loss: 29.4886 - accuracy: 0.7288 - f1: 0.5743 - val_loss: 29.3193 - val_accuracy: 0.8817 - val_f1: 0.6750\n",
            "Epoch 4/5\n",
            "591/591 [==============================] - 534s 904ms/step - loss: 29.4213 - accuracy: 0.7831 - f1: 0.6968 - val_loss: 29.4321 - val_accuracy: 0.8466 - val_f1: 0.6821\n",
            "Epoch 5/5\n",
            "591/591 [==============================] - 534s 903ms/step - loss: 29.3852 - accuracy: 0.8058 - f1: 0.7536 - val_loss: 29.4017 - val_accuracy: 0.8740 - val_f1: 0.7009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdf70538860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9x6amnrt9f1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dfaaf2df-33a5-4ebd-f107-0994078fc59c"
      },
      "source": [
        "Dcnn.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65/65 [==============================] - 20s 305ms/step - loss: 29.4017 - accuracy: 0.8740 - f1: 0.7009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[29.401681900024414, 0.8740384578704834, 0.7009085416793823]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC2Pxb5ov1Ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_qb = dcnn.predict(seq[20972:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9g_MfVww77g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_qb[pred_qb<0.5] = 0  \n",
        "pred_qb[pred_qb>=0.5] = 1  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsPpatirw9kE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93009efe-073b-46d2-83c7-20472e52310a"
      },
      "source": [
        "pred_qb.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGXMBJRKxVo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}